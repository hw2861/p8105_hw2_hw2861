p8105_hw2_hw2861
================
Hongmiao Wang
2022-10-02

##### Question1

In the first step, i import and clean the NYC_Transit_data.

``` r
NYC_Transit =read_csv("./hw2_downloaddata/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor:: clean_names() %>% 
  select(line,station_name,station_latitude,station_longitude,route1:route11,entry,vending,entrance_type,ada) %>%
  mutate(entry=recode(entry, "YES"=TRUE , "NO" = FALSE))
```

The dataset contains information about each entrance and exit for each
subway station in NYC. In the original dataset, there were **32**
variables. I cleaned the dataset by retaining my variables of
interests.A part of the variable on geographical location has been
removed. In the new dataset, It contains the variables as subway lines,
station name, the latitude and longitude of the station,routes
served,entry, vending,entrance type, and ADA compliance. In the
meantime, I standardised the names of the remaining 19 variables. And
the data of the entry variable has been recoded from a character(YES vs
NO) to a logical variable with “TRUE” or “FALSE”. For the dimension,
There are **1868** rows × **19** columns in the resulting dataset. These
data are **NOT tidy** currently. Because there are redundant columns for
route numbers.And the route numbers across 11 columns can be organised
into 1 columns.

\##Further 3 question in Q1 How many distinct stations are there?

There are **465** distinct stations

How many stations are ADA compliant?

``` r
NYC_Transit_AD = filter(NYC_Transit,ada==TRUE)
NYC_Transit_AD_number = nrow(distinct(NYC_Transit_AD, line, station_name))
```

**84** stations are ADA compliant.

What proportion of station entrances / exits without vending allow
entrance?

``` r
NYC_Transit_vending = filter(NYC_Transit,vending == "NO",entry == TRUE)
NYC_Transit_Vending2 = filter(NYC_Transit,vending == "NO")
vending = {nrow(NYC_Transit_vending)}/{nrow(NYC_Transit_Vending2)}
```

**0.3770492** of station entrances / exits without vending allow
entrance.

\##Further question in Q1 As question 1 was not scored and the answer
was given. The standard answers have been **directly pasted** here in
the next chunk.

``` r
NYC_Transit_A=
  NYC_Transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

NYC_Transit_A_ada=
  NYC_Transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

How many distinct stations serve the A train? There are **60** serve the
A train.

Of the stations that serve the A train, There are **17** are ADA
compliant.

##### Question2

Read and clean the Mr. Trash Wheel sheet. I chose to keep the row to
534. This is because row 535 is the summary note “Grand total”.

``` r
Trash_wheel =read_excel("./hw2_downloaddata/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",sheet = "Mr. Trash Wheel", range = "A2:N534",) %>% 
  janitor:: clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls=round(sports_balls,digits=0)) %>% 
  mutate(sports_balls=as.integer(sports_balls))
```

Read and clean the Professor Trash Wheel sheet

``` r
Professor_Trash_wheel =read_excel("./hw2_downloaddata/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",sheet = "Professor Trash Wheel", range = "A2:N116") %>% 
  janitor:: clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls=round(sports_balls,digits=0)) %>% 
  mutate(sports_balls=as.integer(sports_balls))
```

Add an additional variable to both datasets before combining

``` r
Professor_Trash_wheel_new = 
  mutate(Professor_Trash_wheel, wheel_name = "Professor_Trash_wheel")

Trash_wheel_new = mutate(Trash_wheel,
  wheel_name = "Mr.Trash_wheel" )
```

combine the two dataset

``` r
Trash_full = bind_rows(Trash_wheel_new, Professor_Trash_wheel_new) %>%
  janitor::clean_names() 
```

The combining dataset describes weight/volume and types of trash
collected by 2 different Trash wheel(Professor Trash Wheel and Mr. Trash
Wheel). And each collection in this datset has it own dumpster number
and date.These two trash wheel had **524** times
collections(observations) in total between **2014** and **2021** .There
are **15** variables in the combing dataset and **14** variables in each
separate dataset. A new variable for “Trash wheel name” has been added
to the combing dataset.Those variables including weight, volume,along
with the different types of trash. We can also know the home powered
from incinerated trash based on = the variable **home_powered**. For
available data, The total weight of trash collected by Professor Trash
Wheel was **135.5** tons. The total number of sports balls collected by
Mr. Trash Wheel in 2020 was **856** .

##### Question3

clean the data in pols-month.csv

``` r
pols_month= read_csv("./hw2_downloaddata/pols-month.csv") %>% 
  janitor::clean_names () %>% 
  separate(mon, into = c ("year", "month", "day"), sep ="-")%>% 
  mutate(month=as.numeric(month))%>% 
  mutate (month = month.name[month])%>%
  mutate (prez_dem = recode(prez_dem, `1` ="dem", `0` ="gop")) %>% 
  mutate (president = prez_dem)%>% 
  select (-prez_gop,-prez_dem) %>% 
  select (-day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

clean the data in snp.csv

``` r
snp = read_csv("./hw2_downloaddata/snp.csv",show_col_types = FALSE) %>% 
  janitor :: clean_names() %>% 
  separate(date, into =c ("month", "day", "year"), sep = "/") %>% 
  mutate(month=as.numeric(month))%>% 
  mutate (month = month.name[month]) %>% 
  mutate(year=as.numeric(year))%>% 
  mutate (year = if_else(year>49, year +1900, year +2000)) %>% 
  select (year, month,everything())%>% 
  select (-day) 
```

tidy the unemployment data

``` r
unemployment = read_csv( "./hw2_downloaddata/unemployment.csv",show_col_types = FALSE ) %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percent_unemployment" ) %>%
    mutate(month=sapply(month,function(x) grep(paste("(?i)",x,sep=""),month.abb)))%>% 
   mutate (month = month.name[month]) 
```

Join the datasets by merging snp into pols merging unemployment into the
result

``` r
pols_month_pre = mutate(pols_month,year=as.numeric(year))

pols_snp_join = left_join(snp, pols_month_pre, by = c("year","month"))

pols_snp_unemploy = left_join(pols_snp_join, unemployment, by = c("year", "month"))
```

The dataset **pols_month** contains **822** observations of **9**
variables. So There are **822** rows × **9** columns in this dataset.
This dataset is about the number of national politicians from different
parties(Republican vs Democratic) between **1947** and **2015** .The
most important variable in this dataset is **president** ,which gives us
the information about the president’s party on the associated month. The
dataset **snp** contains **787** observations of **3** variables. So
There are **787** rows × **3** columns in this dataset. This dataset is
about the Standard & Poor’s stock market index (S&P) between **1950**
and **2015** .The most important variable in this dataset is **close**
,which gives us the information about the closing values of the S&P
stock index on the associated month. The dataset **unemployment**
contains **816** observations of **3** variables. So There are **816**
rows × **3** columns in this dataset. This dataset is about Unemployment
information between **1948** and **2015** .The most important variable
in this dataset is **percent_unemployment** created by using “long”
format ,which gives us the information about the specific percentage of
unemployment on the associated month. In the dataset, **year** and
**month** are also the important key variables.We merge the three
datasets together by using these two variables. In the final combined
dataset **pols_snp_unemploy**, we can see the government information,
Unemployment percentage and S&P stock index for a given month between
**1950** and **2015** . This makes it easier to find associations
between these variables.
